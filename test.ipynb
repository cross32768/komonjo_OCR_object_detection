{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "import config\n",
    "from dataset import OCRDataset\n",
    "from model import OCRResNet50\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_annotation_list, index_to_utf16 = utils.prepare_selected_annotation_from_dataset_indexes([6, 12])\n",
    "train_annotation_list, validation_annotation_list = train_test_split(selected_annotation_list,\n",
    "                                                                     test_size=0.2,\n",
    "#henkousurukoto                                                                     random_state=config.RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "utf16_to_index = {}\n",
    "for index in index_to_utf16:\n",
    "    utf16_to_index[index_to_utf16[index]] =  index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_annotation \\\n",
    "    = utils.preprocess_annotation(path_to_annotation_csv='../../data/komonjo/200014740/200014740_coordinate.csv',\n",
    "                                  original_image_dir='../../data/komonjo/200014740/images/')\n",
    "test_annotation_list = utils.select_annotation_and_convert_ut16_to_index(preprocessed_annotation, utf16_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = transforms.Compose([transforms.ToTensor(),\n",
    "                         transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = OCRDataset(train_annotation_list, transform=tf)\n",
    "validation_dataset = OCRDataset(validation_annotation_list, transform=tf)\n",
    "test_dataset = OCRDataset(test_annotation_list, transform=tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 16\n",
    "train_loader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batchsize)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batchsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = OCRResNet50(5*config.N_KINDS_OF_CHARACTERS, pretrained_choice=3)\n",
    "net = net.to(device)\n",
    "params = torch.load('../../data/komonjo/logs/experiment_SIN/choice1_90/weight_090.pth')\n",
    "net.load_state_dict(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_dir = '../mAP/input/ground-truth/'\n",
    "pred_dir = '../mAP/input/detection-results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_bbox(char_index, bbox, counter, isGT):\n",
    "    confidence, center_x, center_y, width, height = bbox\n",
    "    min_x = center_x - 0.5*width\n",
    "    min_y = center_y - 0.5*height\n",
    "    max_x = center_x + 0.5*width\n",
    "    max_y = center_y + 0.5*height\n",
    "    \n",
    "    if not isGT:\n",
    "        for_NMS = np.array([confidence, min_x, min_y, max_x, max_y])\n",
    "        remaining_indexes = utils.NMS(for_NMS, border=0.1)\n",
    "        after_NMS = for_NMS[:, remaining_indexes]\n",
    "        confidence, min_x, min_y, max_x, max_y = after_NMS\n",
    "    for i in range(len(confidence)):\n",
    "        c = confidence[i]\n",
    "        minx = min_x[i]\n",
    "        miny = min_y[i]\n",
    "        maxx = max_x[i]\n",
    "        maxy = max_y[i]\n",
    "        if isGT:\n",
    "            with open(gt_dir + '{:03d}.txt'.format(counter), mode='a') as f:\n",
    "                utf16 = index_to_utf16[char_index]\n",
    "                mess = (('\\\\u' + utf16[2:]).encode()).decode('unicode-escape')\n",
    "                f.write('{0} {1} {2} {3} {4}\\n'.format(mess, minx, miny, maxx, maxy))\n",
    "        else:\n",
    "            with open(pred_dir + '{:03d}.txt'.format(counter), mode='a') as f:\n",
    "                utf16 = index_to_utf16[char_index]\n",
    "                mess = (('\\\\u' + utf16[2:]).encode()).decode('unicode-escape')\n",
    "                f.write('{0} {1} {2} {3} {4} {5}\\n'.format(mess, c, minx, miny, maxx, maxy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, data_loader, dataset, border):\n",
    "    counter = -1\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in data_loader:\n",
    "            preds = model(inputs.cuda()).cpu()\n",
    "            for gt_label, pred_label in zip(labels, preds):\n",
    "                counter += 1\n",
    "                with open(gt_dir + '{:03d}.txt'.format(counter), mode='x'):\n",
    "                    1+1\n",
    "                with open(pred_dir + '{:03d}.txt'.format(counter), mode='x'):\n",
    "                    1+1\n",
    "                gt_bboxes = dataset.label2bboxes(gt_label)\n",
    "                pred_bboxes = dataset.label2bboxes(pred_label, confidence_border=border)\n",
    "                for char_index in range(config.N_KINDS_OF_CHARACTERS):\n",
    "                    gt_bbox = gt_bboxes[char_index]\n",
    "                    pred_bbox = pred_bboxes[char_index]\n",
    "                    write_bbox(char_index, gt_bbox, counter, isGT=True)\n",
    "                    write_bbox(char_index, pred_bbox, counter, isGT=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, train_loader, train_dataset, border=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, validation_loader, validation_dataset, border=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(net, test_loader, test_dataset, border=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
